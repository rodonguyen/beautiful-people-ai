# Naval Ravikant Life Advisor AI Clone Project

This document adapts the original **AI Clone Builder** project plan to focus on replicating **Naval Ravikant**'s personality as a **Life Advisor**. Naval's style is calm, philosophical, concise, aphoristic, first-principles oriented, and wisdom-focused—blending Eastern philosophy, rational thinking, wealth creation, leverage, health, happiness, and inner peace.

The core idea remains: ingest Naval's content (tweets, podcast transcripts, *The Almanack of Naval Ravikant*, blog posts), extract/augment insights, and build a conversational AI that responds **as Naval** — thoughtful, non-judgmental, principle-based, often distilling complex ideas into clear, memorable statements.

We prioritize the **bare code + TUI** version for quick validation and testing, as requested.

## 1. Core Concept & Adapted MVP Scope
- **Use Case** — Create a "Naval clone" Life Advisor. Input Naval's quotes, threads, or excerpts. The AI responds to life questions (e.g., "How should I think about happiness?", "Should I chase money or meaning?", "How do I build leverage?") in Naval's voice: calm, reflective, principle-driven, with aphorisms and first-principles reasoning.
- **Key Personality Traits to Emulate** (from Naval's content):
  - Calm, peaceful tone — emphasizes inner peace over excitement.
  - Concise & aphoristic — short, punchy wisdom statements.
  - Philosophical yet practical — blends stoicism, Buddhism, capitalism, leverage.
  - First-principles thinking — breaks down to fundamentals.
  - Core themes: Health > Happiness > Wealth (importance reverse of pursuit order); desire causes suffering; leverage (code, media, capital, labor); specific knowledge; judgment; compound interest in habits/money/relationships.
  - Responses often reframe questions, reduce desire, promote clarity/meditation, avoid status games.
- **MVP Features**:
  - Manual paste of Naval content (quotes, threads, excerpts from *Almanack*).
  - Enhanced extraction + augmentation tailored to Naval's style (generalize to principles, infer mental models).
  - RAG-based clone that responds **as Naval**.
  - TUI (terminal menu) for input, creation, querying.
- **Exclusions** — No multi-clone yet; no auto-fetching (add later via RSS or manual copy from navalmanack.com or @naval tweets).

## 2. Tech Stack (Bare/TUI Version)
- **Language** — Python 3.10+.
- **AI/ML** — Sentence Transformers (embeddings), FAISS (vector store), LangChain (RAG pipeline).
- **LLM** — Anthropic API (Claude). Set `ANTHROPIC_API_KEY` environment variable. Use `claude-haiku-4-5-20251001` for speed/cost during development; swap to `claude-sonnet-4-5-20250929` for better reasoning quality.
- **Interface** — Pure Python TUI with `rich` for terminal formatting.
- **Storage** — JSON file (`data/insights.json`) for persistence across sessions.
- **Install** — `pip install anthropic langchain langchain-anthropic langchain-community faiss-cpu sentence-transformers rich`

## 3. Project Structure
```
src/
  naval_clone_tui.py     # Main TUI entrypoint
  extractor.py           # Extraction + augmentation via Anthropic API
  clone.py               # Vectorstore build + RAG query
  storage.py             # JSON load/save helpers
data/
  insights.json          # Persisted insights (auto-created)
.env                     # ANTHROPIC_API_KEY=sk-ant-...
requirements.txt
```

## 4. Insight Extraction & Augmentation (Naval-Tailored)
- **Augmentation Step** (critical for Naval mimicry):
  - Infer core principle/mental model from the original text.
  - Generalize to a timeless rule.
  - Rephrase in aphoristic, calm style.
  - Tag related Naval themes (happiness, peace, desire, leverage, specific knowledge, compounding).
- **Example Input** — "Desire is a contract you make with yourself to be unhappy until you get what you want."
  - Augmented Output:
    - specific: Desire creates unhappiness until fulfilled.
    - causation: Attachment to outcomes → mental suffering.
    - generalized: "Peace comes from dropping unnecessary desires."
    - naval-style aphorism: "Desire is suffering in anticipation."

**Augmentation Prompt** (sent to Claude via Anthropic API):
```
From this Naval Ravikant statement or excerpt:
"{text}"

Reply in this exact format:
1. KEY INSIGHT: <concise summary of the core idea>
2. MENTAL MODEL: <underlying causation or reasoning pattern>
3. PRINCIPLE: <broader, timeless life principle>
4. APHORISM: <calm, Naval-style aphoristic restatement>
5. THEMES: <comma-separated Naval themes: e.g., desire, peace, leverage, specific knowledge, happiness, wealth, compounding, judgment>
```

## 5. Code Structure

### 5.1 `requirements.txt`
```
anthropic
langchain
langchain-anthropic
langchain-community
faiss-cpu
sentence-transformers
rich
```

### 5.2 `.env`
```
ANTHROPIC_API_KEY=sk-ant-...
```

### 5.3 `src/storage.py`
```python
import json
import os

INSIGHTS_PATH = "data/insights.json"

def load_insights() -> list[dict]:
    if not os.path.exists(INSIGHTS_PATH):
        return []
    with open(INSIGHTS_PATH) as f:
        return json.load(f)

def save_insights(insights: list[dict]) -> None:
    os.makedirs("data", exist_ok=True)
    with open(INSIGHTS_PATH, "w") as f:
        json.dump(insights, f, indent=2)
```

### 5.4 `src/extractor.py`
```python
import anthropic

client = anthropic.Anthropic()  # reads ANTHROPIC_API_KEY from env

AUGMENT_PROMPT = """From this Naval Ravikant statement or excerpt:
"{text}"

Reply in this exact format:
1. KEY INSIGHT: <concise summary of the core idea>
2. MENTAL MODEL: <underlying causation or reasoning pattern>
3. PRINCIPLE: <broader, timeless life principle>
4. APHORISM: <calm, Naval-style aphoristic restatement>
5. THEMES: <comma-separated Naval themes>"""


def extract_and_augment(text: str) -> dict:
    prompt = AUGMENT_PROMPT.format(text=text)
    message = client.messages.create(
        model="claude-haiku-4-5-20251001",
        max_tokens=512,
        messages=[{"role": "user", "content": prompt}]
    )
    response = message.content[0].text
    lines = [l.strip() for l in response.splitlines() if l.strip()]

    def extract_field(prefix):
        for line in lines:
            if line.upper().startswith(prefix):
                return line.split(":", 1)[-1].strip()
        return ""

    return {
        "original": text,
        "key_insight": extract_field("1. KEY INSIGHT"),
        "mental_model": extract_field("2. MENTAL MODEL"),
        "principle": extract_field("3. PRINCIPLE"),
        "aphorism": extract_field("4. APHORISM"),
        "themes": extract_field("5. THEMES"),
    }
```

### 5.5 `src/clone.py`
```python
import anthropic
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings

embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
client = anthropic.Anthropic()

NAVAL_SYSTEM_PROMPT = """You are Naval Ravikant. Respond as Naval: calm, philosophical, concise.
Use aphorisms and first-principles thinking. Focus on peace, leverage, specific knowledge,
happiness over status games, and reducing unnecessary desire. Never be preachy.
Keep responses under 5 sentences unless depth is needed."""


def build_vectorstore(insights: list[dict]) -> FAISS:
    texts = [
        f"{i['aphorism']} | {i['principle']} | {i['themes']}"
        for i in insights
    ]
    return FAISS.from_texts(texts, embeddings)


def query_naval(vectorstore: FAISS, question: str) -> str:
    docs = vectorstore.similarity_search(question, k=3)
    context = "\n".join(d.page_content for d in docs)

    message = client.messages.create(
        model="claude-haiku-4-5-20251001",
        max_tokens=512,
        system=NAVAL_SYSTEM_PROMPT,
        messages=[{
            "role": "user",
            "content": f"Relevant wisdom from your writings:\n{context}\n\nQuestion: {question}"
        }]
    )
    return message.content[0].text
```

### 5.6 `src/naval_clone_tui.py`
```python
import os
from dotenv import load_dotenv
from rich.console import Console
from rich.prompt import Prompt
from storage import load_insights, save_insights
from extractor import extract_and_augment
from clone import build_vectorstore, query_naval

load_dotenv()
console = Console()


def get_multiline(prompt_text: str) -> str:
    console.print(prompt_text, style="bold cyan")
    console.print("[dim]Type your text. Enter END on a new line when done.[/dim]")
    lines = []
    while True:
        line = input()
        if line.strip().upper() == "END":
            break
        lines.append(line)
    return "\n".join(lines)


def main():
    insights = load_insights()
    vectorstore = build_vectorstore(insights) if insights else None

    while True:
        console.print("\n[bold green]Naval Ravikant Life Advisor Clone[/bold green]")
        console.print(f"[dim]{len(insights)} insight(s) stored[/dim]")
        console.print("1 → Add Naval content (quote / excerpt)")
        console.print("2 → Ask Naval a life question")
        console.print("3 → Show stored insights")
        console.print("4 → Exit")
        choice = Prompt.ask("Choice", choices=["1", "2", "3", "4"], default="4")

        if choice == "1":
            content = get_multiline("Paste Naval quote/thread/excerpt:")
            if not content.strip():
                continue
            console.print("[dim]Extracting and augmenting...[/dim]")
            insight = extract_and_augment(content)
            insights.append(insight)
            save_insights(insights)
            vectorstore = build_vectorstore(insights)  # rebuild with new insight
            console.print(f"[green]Added:[/green] {insight['aphorism']}")

        elif choice == "2":
            if not vectorstore:
                console.print("[red]No insights yet. Add content first (option 1).[/red]")
                continue
            while True:
                question = Prompt.ask("\nAsk Naval (or 'back')")
                if question.lower() == "back":
                    break
                console.print("[dim]Thinking...[/dim]")
                response = query_naval(vectorstore, question)
                console.print(f"\n[bold yellow]Naval:[/bold yellow] {response}\n")

        elif choice == "3":
            if not insights:
                console.print("[yellow]No insights stored.[/yellow]")
            for i, ins in enumerate(insights, 1):
                console.print(f"[bold]{i}.[/bold] {ins.get('aphorism') or ins.get('key_insight', '—')}")
                console.print(f"   [dim]{ins.get('themes', '')}[/dim]")

        elif choice == "4":
            console.print("[bold]Peace be with you... Exiting.[/bold]")
            break


if __name__ == "__main__":
    main()
```

## 6. Validation & Testing Plan
- Setup: `cp .env.example .env` → fill in `ANTHROPIC_API_KEY`
- Run: `cd src && python naval_clone_tui.py`
- Step 1: Paste 3–5 famous Naval quotes/threads (from *Almanack*, "How to Get Rich" thread, @naval).
- Step 2: Query examples:
  - "How do I become happy?"
  - "Should I optimize for money or peace?"
  - "What is leverage in life?"
- Check: Does it respond calmly, aphoristically, with Naval-like reframing?
- Iterate: Tune `NAVAL_SYSTEM_PROMPT` and the augmentation prompt for tone. Swap to `claude-sonnet-4-5-20250929` if responses need more depth.
- Next: Add web UI, auto-ingest from navalmanack.com or X.

This bare TUI lets you rapidly test if the clone captures Naval's essence. Once validated, expand to full app. Peace.
